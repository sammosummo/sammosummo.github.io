---
layout: post
title: "Bayesian model of recognition memory"
date: 2017-11-22
categories:
- Bayesian
- Psychophysics
description:
image: https://sammosummo.github.io/images/glass-tears-1932.jpg
image-sm: https://sammosummo.github.io/images/glass-tears-1932-sm.jpg
image-description: "Glass Tears (1932) by Man Ray"
---
Signal detection theory (SDT) is useful tool for studying recognition memory[<sup>1</sup>]. Here, I describe a Bayesian hierarchical SDT model suitable for analysing data from recognition-memory experiments.

[<sup>1</sup>]: https://www.ncbi.nlm.nih.gov/pubmed/4867890 "Kintsch, W. (1967). Memory and decision aspects of recognition learning. Psychological Review, 74(6), 496–504."

A typical recognition-memory experiment consists of two phases. During the learning phase, subjects are presented with a sequence of stimuli (items). Later, during the test phase, subjects are presented with a mixture of new items (foils) and old items (targets), and are required to discriminate them. Recognition-memory experiments often use confidence ratings. For example, subjects may be asked whether they remember the items by choosing from the following response options: ‘definitely no’, ‘perhaps no’, ‘perhaps yes’, and ‘definitely yes’. In what follows, I assume that there is always an even number of response options — otherwise, a small modification to the model is required.

Let $$y$$ denote a subject’s response on a given trial with $$y =1$$ denoting ‘definitely no’, $$y=2$$ denoting ‘perhaps no’, and so on. The probability distribution of $$y$$ can be written as follows: 

$$
y_{i_j}\sim\textrm{Categorical}\left(p_{i_{j_1}},p_{i_{j_2}},\dots{},p_{i_{j_K}}\right)
$$

where $$i$$ indexes the subject, and $$j$$ indexes the trial, and $$K$$ is the number of response options. 

Every SDT model contains a perceptual component and a decision component (see [<sup>2</sup>]). The perceptual component describes how observations are generated. Here, we assume that a subject creates a latent variable corresponding to the perceived familiarity of the item on a given trial, denoted by $$\psi$$. A negative value of $$\psi$$ means that the item is perceived as unfamiliar, whereas a positive value means that the item is perceived as familiar. When the stimulus is a foil, $$\psi$$ is drawn from a Gaussian probability distribution with mean $$a_\textrm{foil}$$ and variance $$s_\textrm{foil}^2$$, Without any loss of generality, we set $$s_\textrm{foil}^2=1$$. When the stimulus is a target, $$\psi$$ is drawn from a Gaussian probability distribution with mean $$a_\textrm{target}$$ and variance $$s_\textrm{target}^2$$. Since the foil variance is fixed, it is more convenient to denote the target variance simply by $$s^2$$. A compact expression for $$\psi$$ is

$$
\psi_{i_j}=a_{\textrm{foil}_{i_j}}\cdot\left(1-z_{i_j}\right) + a_{\textrm{target}_{i_j}}\cdot{}z_{i_j} + s_{i_j}^z\cdot\epsilon_{i_j}
$$

where $$\epsilon\sim\textrm{Normal}\left(0, 1\right)$$, and where $$z=0$$ for foils and $$z=1$$ for targets.

[<sup>2</sup>]: https://doi.org/10.1016/j.jmp.2011.01.002 "DeCarlo, L. T. (2011). Signal detection theory with item effects. Journal of Mathematical Psychology, 55, 229–239."

The decision component of the model describes how responses are generated. Responses are based on $$\psi$$ in relation to several criteria. Specifically, the decision rule is

$$
y_{i_j}=k\textrm{   if   }c_{i_{j_{k-1}}} < \psi_{i_j} \le c_{i_{j_{k}}}
$$

where $$c=-\infty$$ if $$k=0$$, $$c=0$$ if $$k=K/2$$ (hence the need for even $$K$$), $$c=\infty$$ if $$k=K$$. Any remaining criteria are free to vary.

At this point, it is worth pointing out that while the decision process allows criteria to vary between subjects and items (hence subscript $$i$$s and $$j$$s on $$c$$), criteria are almost always assumed to be stable across items. Whether this is true in practice is a big can of worms that I don’t want to open here. We could, if we wanted, extend the model to test this assumption; perhaps I’ll do this in a future post. For now, interested readers may wish to consult the excellent paper on this topic by Cabrera and colleagues[<sup>3</sup>].

[<sup>3</sup>]: https://doi.org/10.1016/j.jmp.2011.01.002 "Cabrera, C. A., Lu, Z. L., & Dosher, B. A. (2015). Separating decision and encoding noise in signal detection tasks. Psychological Review, 122(3), 429–460."


With the decision and perceptual components defined, we derive the following conditional probabilities

$$
\textrm{Pr}\left(y_{i_j}=k\mid{}z_{i_j}=0\right)=\Phi\left(a_{\textrm{foil}_{i_j}}-c_{i_{j_k}}\right)-\Phi\left(a_{\textrm{foil}_{i_j}}-c_{i_{j_{k-1}}}\right)\\
\textrm{Pr}\left(y_{i_j}=k\mid{}z_{i_j}=1\right)=\Phi\left(\frac{a_{\textrm{target}_{i_j}}-c_{i_{j_k}}}{s_{i_j}}\right)-\Phi\left(\frac{a_{\textrm{target}_{i_j}}-c_{i_{j_{k-1}}}}{s_{i_j}}\right)
$$

The above can be written more compactly as

$$
p_{i_{j_k}}=\left[\Phi\left(a_{\textrm{foil}_{i_j}}-c_{i_{j_k}}\right)-\Phi\left(a_{\textrm{foil}_{i_j}}-c_{i_{j_{k-1}}}\right)\right]\cdot\left(1-z_{i_j}\right)
$$