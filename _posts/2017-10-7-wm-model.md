---
layout: post
title: "Bayesian model of working-memory capacity"
date: 2017-02-19
categories:
- Bayesian
- Psychophysics
description:
image: https://sammosummo.github.io/images/memory-1948.jpg
image-sm: https://sammosummo.github.io/images/memory-1948-sm.jpg
image-description: "Memory by Rene Margitte (1948)"
---

Working memory (WM) is the name given to the memory system that stores information over short periods, which is strictly limited in terms of duration and capacity. In this post, I present a model for measuring WM capacity from psychophysical data using Bayesian hierarchical inference.

**(Disclaimer: Some of what appears below was taken from an earlier post on my previous blog. The code has been improved, and I have included a plug for one of my recent papers.)**

The nature of WM capacity limitation is a source of current debate. Some researchers argue that WM is *slots-based*[<sup>1</sup>], stating that we can remember up to a fixed number of discrete items at once. Others suggest that WM capacity is a finite *flexible resource*[<sup>2</sup>]. Personally, I lean more towards the latter view. However, item-based storage has long been the dominant view, and the maximum number of items stored in WM, denoted by \\( k \\), remains a popular dependent variable in the cognitive sciences.

[<sup>1</sup>]: https://doi.org/10.1016/j.tics.2013.06.006 "Luck, S.J., & Vogel, E.K. (2013). Visual working memory capacity: From psychophysics and neurobiology to individual differences. Trends in Cognitive Sciences, 17(8), 391–400."

[<sup>2</sup>]: https://doi.org/10.1038/nn.3655 "Ma, W. J., Hussain, M. & Bays, P. M. (2014). Changing concepts of working memory. Nature Neuroscience, 17, 347–356."

A simple way of measuring \\( k \\) is to apply a formula proposed by either Pashler[<sup>3</sup>] or Cowan[<sup>4</sup>] to the data from a change-detection task. On each trial in a change-detection task, the subject is presented with a stimulus comprising several distinct items (e.g., a visual array of objects) and after a few seconds, a second stimulus is presented. The second stimulus contains at least one item from the original stimulus (the probed item), which may or may not have changed in some way, and the subject indicates whether a change occurred. The choice of formula depends on whether the second stimulus also contains the remaining items from the original stimulus: if so, Pashler’s formula should be used; if it contains just the probed item, Cowan’s should be used.

[<sup>3</sup>]: https://www.ncbi.nlm.nih.gov/pubmed/3226885 "Pashler, H. (1988). Familiarity and visual change detection. Perception & Psychophysics, 44(4), 369–378."

[<sup>4</sup>]: https://www.ncbi.nlm.nih.gov/pubmed/11515286 "Cowan, N. (2001). The magic number 4 in short-term memory: A reconsideration of mental storage capacity. Behavioral and Brain Sciences, 24(1), 87–114."

These formulae are easy to implement and are widely used in research, but there are several problems with them. First, using these formulae, \\( k \\) can only be calculated from trials with the same set size — experiments typically include trials with various set sizes, so estimates of \\( k \\) must be calculated separately for each set size and then combined, rather than calculating a single estimate from all the data. Second, since \\( k \\) can never exceed the set size, it is systematically underestimated whenever the set size is smaller than the true \\( k \\). Third, the formulae can yield negative values of \\( k \\), which are obviously impossible. Fourth, the formulae cannot be used to calculate \\( k \\) at all when performance is at ceiling or floor.

To remedy these issues, Morey[<sup>5</sup>] formalised a Bayesian hierarchical model for the measurement of WM capacity from change-detection tasks. The model largely deals with the problems listed above, and is much more efficient (it recovers parameters more accurately) than those formulae when there are few data. Morey provides his own software to fit the model[<sup>6</sup>].

[<sup>5</sup>]: https://doi.org/10.1016/j.jmp.2010.08.008 "Morey, R. D. (2011). A hierarchical Bayesian model for the measurement of working memory capacity. Journal of Mathematical Psychology, 55, 8–24"

[<sup>6</sup>]: https://dx.doi.org/10.3758%2Fs13428-011-0114-8 "Morey, R. D. & Morey, C. C. (2011). WoMMBAT: A user interface for hierarchical Bayesian estimation of working memory capacity. Behavior Research Methods, 43(4), 1044–1065."

I have implemented my own version of this model using [PyMC3](http://docs.pymc.io/), a Python package for Bayesian modelling[<sup>7</sup>]. My version is not exactly the same as Morey’s. For example, my version uses PyMC3’s built-in inference methods, which are vastly more efficient than earlier ones (e.g., Metropolis) when sampling from hierarchical models, and my model also contains a re-parameterisation trick to deal with the issue of funneling. The code only applies to the Cowan style of change-detection tasks, although it would be easy to modify it to apply to Pashler-style tasks, or indeed any other variation, provided the decision rule can be specified.

[<sup>7</sup>]: https://doi.org/10.7717/peerj-cs.55 "Salvatier, J., Wiecki, T. V., & Fonnesbeck, C. (2016). Probabilistic programming in Python using PyMC3. PeerJ Computer Science, 2:e55."


The model
---------

The model assumes that, on a given trial, the subject may or may not suffer a lapse in attention. When a lapse occurs, the subject simply guesses same or different, with no regard for the stimulus. When the subject does not lapse, they perform the task properly. The probability of a non-lapse is denoted by \\( z \\).

On non-lapse trials, the subject remembers up to \\( k \\) items from the stimulus. If the set size, \\( M \\), is less than or equal to \\( k \\), all of the items are remembered, but if \\( M \\) exceeds \\( k \\), a random selection of \\( k \\) items are remembered.

If the probed item was one of the ones remembered, the subject correctly responds same or different, depending on the type of trial. If the probed item was not remembered, the subject guesses, just like on a lapse trial. The probability that the subject guesses same is assumed to be fixed, and is denoted by \\( g \\).

With the decision process fully defined, we can simulate the subject’s response on a given trial, provided we know the trial conditions, namely the set size and whether the correct response was same or different, and the values of the decision parameters, \\(z \\), \\( k \\), and \\( g \\). The following Python function generates responses:

~~~ python
def trial(M, different, z, k, g):
    # Returns `True` if different
    from numpy.random import uniform
    if uniform() > z:
        if uniform() < g:
            return True
        else:
            return False
    else:
        if uniform() < k / float(M):
            return different
        else:
            if uniform() < g:
                return True
        else:
            return False
~~~


To estimate the decision parameters from data, we need to distinguish between *hits* and *false alarms*, in a similar way to signal detection theory. We arbitrarily define a hit as a correct response on a different trial, and a false alarm as an incorrect response on a different trial. The observed number of hits, \\( H \\), follows the probability distribution

$$
H_{i_j} \sim \textrm{Binomial}\left(h_{i_j},D_{i_j}\right)\textrm{,}
$$

where \\( h \\) is the hit probability, \\( D \\) is the number of different trials, \\( i \\) indexes the subject and/or condition, and \\( j \\) indexes the set size. (I assume that the experiment includes trials with more than one set size per subject/condition, which is almost always true.) The corresponding probability distribution for the observed number of false alarms, \\( F \\), is

$$
F_{i_j} \sim \textrm{Binomial}\left(f_{i_j},S_{i_j}\right)\textrm{,}
$$

where  \\( f \\) is the false-alarm probability and \\( S \\) is the number of same trials. (I have tried to stick to the conventions that upper-case variables represent discrete values, and lower-case variables represent continuous values.)

The relationships between \\( h \\) and \\( f \\), the trial conditions, and the decision parameters defined by these equations:

$$
h_{i_j}=\left(1-z_{i}\right)g_{i}+z_{i}q_{i_j}+z_{i}\left(1-q_{i_j}\right)g_i\\
f_{i_j}=\left(1-z_i\right)g_i+z_i\left(1-q_{i_j}\right)g_i\textrm{,}
$$

where

$$
q_{i_j}=\min\left(1,\frac{k_i}{M_{i_j}}\right)\textrm{.}
$$

It is generally a good idea to do inference on normally distributed variables. However, \\( k \\) cannot be normal, because negative values of \\( k \\) are impossible, and neither can \\( g \\) nor \\( z \\), because they are probabilities and must fall between 0 and 1. Therefore, we apply the following link functions

$$
\k_{i}=\max\left(\kappa_i, 0\right)\textrm{,}\\
\g_{i}=\textrm{logistic}\left(\gamma_i\right)\\
$$
z_{i}=\textrm{logistic}\left(\zeta_i\right)\textrm{.}
$$

The new Greek-lettered variables (transformed decision parameters) are determined by

$$
\kappa_i=\mu_{(\kappa)_i}+\delta_{(\kappa)_i}\sigma_{(\kappa)}\\
\gamma_i=\mu_{(\gamma)_i}+\delta_{(\gamma)_i}\sigma_{(\gamma)}\\
\zeta_i=\mu_{(\zeta)_i}+\delta_{(\zeta)_i}\sigma_{(\zeta)}\textrm{.}
$$

Here, the $$\mu$$ variables represent the group-level trends in the transformed decision parameters. Notice that they all have subscript \\( i \\)s, indicating that they are actually elements within vectors. These vectors are defined as follows:

$$
\vec{\mu_{\left(\kappa\right)}}=\begin{bmatrix} \mu_{(\kappa)_{i=0}} \\ \mu_{(\kappa)_{i=1}} \\ \vdots \\ \mu_{(\kappa)_{i=N}}\end{bmatrix}=\mathbf{X}_{\left(\kappa\right)}\vec{\beta_{\left(\kappa\right)}}\\
\vec{\mu_{\left(\gamma\right)}}=\begin{bmatrix} \mu_{(\gamma)_{i=0}} \\ \mu_{(\gamma)_{i=1}} \\ \vdots \\ \mu_{(\gamma)_{i=N}}\end{bmatrix}=\mathbf{X}_{\left(\gamma\right)}\vec{\beta_{\left(\gamma\right)}}\\
\vec{\mu_{\left(\zeta\right)}}=\begin{bmatrix} \mu_{(\zeta)_{i=0}} \\ \mu_{(\zeta)_{i=1}} \\ \vdots \\ \mu_{(\zeta)_{i=N}}\end{bmatrix}=\mathbf{X}_{\left(\zeta\right)}\vec{\beta_{\left(\zeta\right)}}\textrm{,}
$$

where \\( N\\) denotes the total number of subjects/conditions, \\( \mathbf{X} \\) denotes a design matrix, and \\( \vec{\beta} \\) denotes a vector of regression coefficients. Put simply, we have placed linear models on each $$\mu$$. Why? Because it allows us to specify and measure the effects of any *independent variables* included in the design matrices on WM capacity ($$k$$), response bias ($$g$$), and lapse rate ($$z$$). The model deals with the fact that these variables are not normally distributed by placing the linear models on their transformations. Moreover, because the model is hierarchical, it applies regularisation or *shrinkage* to the lower-level stochastic variables, and therefore should deal with outliers and/or noisy data better than a traditional (non-hierarchical) analysis of the data. The regression coefficients are also stochastic variables, to which we assign somewhat vague priors:

$$
\beta_{(\kappa)_a}\sim{}\textrm{Cauchy}\left(0, 2.5\right)\\
\beta_{(\kappa)_b}\sim{}\textrm{Cauchy}\left(0, 2.5\right)\\
\beta_{(\kappa)_c}\sim{}\textrm{Cauchy}\left(0, 2.5\right)\textrm{,}
$$

where \\(a \\), \\(b \\), and \\(c \\) index the coefficients. The value of 2.5 seemed reasonable to me, although it was not based on rigorous testing, so anyone using this code should consider modifying it if necessary.

Returning to the definitions of the transformed decision parameters, the $$\delta$$ variables represent the unique subject/condition offsets from the group-level trends, and the $$\sigma$$ variables represent the average size of these offsets (i.e., their standard deviations). They are all stochastic variables, and have the following probability distributions: