---
layout: post
title: Python packages for scientists
date: 2018-07-05
categories:
- Opinion
description:
image: https://sammosummo.github.io/images/1280px-Jean-Léon_Gérôme_003.jpg
image-sm: https://sammosummo.github.io/images/640px-Jean-Léon_Gérôme_003.jpg
image-description: "Bonaparte Before the Sphinx (1886) by Jean-Léon Gérôme"
---

Python is my go-to programming language. As a scientist, a big portion of my time is spent munging, cleaning, analysing and visualising data — I find myself using Python in virtually all of these tasks, in one way or another. Like R, one of the key advantages of Python for scientists is the availability of third-party packages. Besides the obvious ones like NumPy and SciPy, I find many smaller, more obscure packages extremely useful. Oftentimes I use these smaller packages to solve tasks for which they were not originally designed. I decided to list them here.

Just a quick note about my setup. My main work computer and personal laptop are both Macs, and I use Anaconda Python exclusively. I use the latest version of Python 3 (3.6 at the time of writing) and update all packages regularly. I use PyCharm (professional edition; free for academics) as my IDE, with one ‘project’ per paper/task I’m working on. Each project has its own conda environment with the same name.

The big ones

These are the packages everyone probably already knows about. I list them here just for completeness.

NumPy is literally the fundamental package for scientific computing with Python, adding support for arrays and matrices, along with many high-level mathematical functions. I’m sure everyone is familiar with it already. Most of the packages listed below depend on NumPy, and much can be done without ever calling NumPy directly.

SciPy library is the second-most fundamental package for science after NumPy, containing a huge number of numerical routines. Technically, SciPy refers to the ‘SciPy stack’, which includes NumPy.

pandas is the major package for data manipulation in Python. Like NumPy (one of its dependencies), pandas is extremely popular and I assume most scientists know about it already. It is a common dependency of other packages on this list. I frequently find myself loading and saving data in various formats using pandas, along with rudimentary data manipulation/analysis, such as performing transformations and screening for outliers.

matplotlib is the major Python package for data visualisation. My perspective might be skewed, but I have the impression that matplotlib is slightly less universally praised among scientists than some of the other packages on this list. It can be quite tricky to get matplotlib to do exactly what you want. Nevertheless, I find myself using routinely.

statsmodels contains many classes and functions for fitting statistical models and performing statistical tests. I’m on the fence about this package. On the one hand, it’s really big, and seems mostly well-written and documented. On the other hand, it seems to be missing some fairly common models and tests (e.g., repeated-measures ANOVA). I have also noticed some differences in the results and those produced by R (e.g., FDR correction of p-values). I’ve found myself reproducing results obtained from statsmodels in R before accepting them and moving on, which kinda defeats the purpose.

scikits-learn is a package for machine learning. I’m far from an expert in machine learning and the things I do with this package are pretty basic (e.g., clustering, factor analysis). Nevertheless, it works marvellously.

Data manipulation

PyTables adds support for the HDF5 file format to pandas and is required to use the `to_hdf()` and `read_hdf()` methods. Although it is optional, I always install it. I try to restrict myself to only two file formats for data: CSV for small data sets and HDF5 for larger sets.

tabview was a recent discovery that became immediately indispensable. It allows Excel-like viewing of CSV files from the terminal. Much of my work is done in remote terminal sessions, running jobs in parallel on high-performance computing clusters. tabview makes it easy to quickly spot-check the contents of data files from the command line like this:

```
tabview my_data.csv
```


tqdm displays a progress bar in the terminal when looping. It’s very easy to use and provides convenient estimates of the time elapsed, time remaining and time per iteration. Like tabview, it is very helpful when running code remotely. Here is a simple use case:

```
from tqdm import tqdm

mylonglist = […]

for i in tqdm(mylonglist):
    # do stuff here
    pass
```

Visualisation

seaborn is a high-level package for data visualisation built on top of matplotlib. It contains a few dozen core plotting functions, all of which try to do something useful when called with a minimal set of arguments. Plots are customisable through additional parameters. It also contains a number of ‘themes’ and colour maps that can be applied to any matplotlib plots (not just those from seaborn) to make them more visually appealing or suitable for publication.

cmocean provides additional colour maps for matplotlib. They were designed with oceanography in mind, but in my opinion they are the best colour maps currently available for Python regardless of scientific area. I’m currently using them for plotting heritability estimates on the human cortical surface.

Speaking of cortical surfaces, the author of seaborn also produced PySurfer. Unfortunately, it doesn’t work in Python 3.

Data analysis

patsy (‘it’s only a model’) uses an R-like mini language to create design matrices for statistical models such as for linear regression. I use it in conjunction with other statistical packages like PyMC3 (see below).

PyMC3 is the current state-of-the-art package for Bayesian statistical inference. It contains many of the same features as Stan, such as Hamiltonian Monte Carlo and variational inference. I have used this package in published work (see here). Recently it was announced that Theano (on which PyMC3 relies for much of its computation) was no longer being developed. It remains to be seen whether this decision will impede the development of PyMC3 in the long run. For the time being, however, it is continuing to evolve and I will continue to use it in future projects.

HDDM is a Python package for fitting the drift-diffusion model to experimental data from tasks of two-choice decision making (see here). It is a somewhat niche package. It depends on PyMC2, which is now obsolete. It would be great if it could be re-written with PyMC3 …

Running psychological experiments

pygame is a package for making multimedia applications (like games) built on top of the SDL library. The developers themselves describe pygame as ‘not the best game library’, as is intended as a learning tool rather than a serious package. In the early days of my career I wrote many of my experiments using pygame (I was just starting out, after all). I ended up relying on it for far too long simply because I didn’t want to re-write my code. I wouldn’t recommend it for serious use.

PyQt5 (Qt5 bindings for Python) is my pygame replacement. PyQt5 has a steeper learning curve than pygame, but once you get used to its highly object-oriented, signal-and-slots model it is actually incredibly powerful and easy to use. It is the primary package behind the new version of my neuropsychological battery, Charlie 2.

brain is another niche package, this time for modelling neuronal spiking. I only ever used its sub-package brian hears, which contained some very nice classes and functions for sound synthesis, for running psychoacoustical experiments. brian was superseded by brain2, however brian hears wasn’t ported along with it.

loris is yet another niche package I’ve used for sound modelling and synthesis.

Miscellany

Black (‘any colour you like’) is an ‘uncompromising’ Python code formatter. Black can be called from the command line like this:

```
black myscript.py
```

The script is formatted in-place according the package’s own rules without the user having any choice in the matter. In my opinion, this is a great idea. It ensures that your code is highly readable and removes the temptation to waste time on hand-formatting.

Packages I don’t use

I’ve tried to use MayaVi a couple of times but always found it too difficult.

PsychoPy is a package designed specifically for psychological experiments. Given my background, I should have been all over PsychoPy, but I never really liked it and wrote a lot of what it could do from scratch myself. Perhaps it has improved over time, but I no longer have much use for it.






