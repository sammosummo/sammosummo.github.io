---
layout: post
title: Python packages for scientists
date: 2018-07-05
categories:
- Opinion
description:
image: https://sammosummo.github.io/images/1280px_003.jpg
image-sm: https://sammosummo.github.io/images/640px_003.jpg
image-description: "Bonaparte Before the Sphinx (1886) by Jean-Léon Gérôme"
---

Python is my go-to programming language. As a scientist, a big portion of my time is spent munging, cleaning, analysing and visualising data — I find myself using Python in virtually all of these tasks, in one way or another. Like R, one of the key advantages of Python for scientists is the availability of third-party packages. Besides the obvious ones like NumPy and SciPy, I find many smaller, more obscure packages extremely useful. Oftentimes I use these smaller packages to solve tasks for which they were not originally designed. I decided to list them here.

Just a quick note about my setup. My main work computer and personal laptop are both Macs, and I use [Anaconda distribution of Python](https://www.anaconda.com/download) exclusively. I use the latest version of Python 3 (3.6 at the time of writing) and update all packages regularly. I use [PyCharm](https://www.jetbrains.com/pycharm) (professional edition; free for academics) as my IDE, with one ‘project’ per paper/task I’m working on. Each project has its own [conda environment](https://conda.io/docs/user-guide/tasks/manage-environments.html) with the same name.

## The big ones

These are the packages everyone probably already knows about. I list them here just for completeness.

[NumPy](http://www.numpy.org) is literally the fundamental package for scientific computing with Python, adding support for arrays and matrices, along with many high-level mathematical functions. I’m sure everyone is familiar with it already. Most of the packages listed below depend on NumPy, and much can be done without ever calling NumPy directly.

[SciPy library](https://www.scipy.org/scipylib/index.html) is the second-most fundamental package for science after NumPy, containing a huge number of numerical routines. Technically, SciPy refers to the [‘SciPy stack’](https://www.scipy.org), which includes NumPy.

[pandas](https://pandas.pydata.org) is the major package for data manipulation in Python. Like NumPy (one of its dependencies), pandas is extremely popular and I assume most scientists know about it already. It is a common dependency of other packages on this list. I frequently find myself loading and saving data in various formats using pandas, along with rudimentary data manipulation/analysis, such as performing transformations and screening for outliers.

[matplotlib](https://matplotlib.org) is the major Python package for data visualisation. My perspective might be skewed, but I have the impression that matplotlib is slightly less universally praised among scientists than some of the other packages on this list. It can be quite tricky to get matplotlib to do exactly what you want. Nevertheless, I find myself using routinely, especially the [`pyplot` API](https://matplotlib.org/api/pyplot_summary.html).

[statsmodels](http://www.statsmodels.org/stable/index.html) contains many classes and functions for fitting statistical models and performing statistical tests. I’m on the fence about this package. On the one hand, it’s really big, and seems mostly well-written and documented. On the other hand, it seems to be missing some fairly common models and tests (e.g., [repeated-measures ANOVA](https://github.com/statsmodels/statsmodels/issues/749)). I have also noticed some differences in the results and those produced by R (e.g., FDR correction of p-values). I’ve found myself reproducing results obtained from statsmodels in R before accepting them and moving on, which kinda defeats the purpose.

![scikits demo](http://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png)

[scikits-learn](http://scikit-learn.org/stable/) is a package for machine learning. I’m far from an expert in machine learning and the things I do with this package are pretty basic (e.g., clustering, factor analysis). Nevertheless, it works marvellously.

## Data manipulation

[PyTables](https://www.pytables.org) adds support for the HDF5 file format to pandas and is required to use the `to_hdf()` and `read_hdf()` methods. Although it is optional, I always install it. I try to restrict myself to only two file formats for data: CSV for small data sets and HDF5 for larger sets.

[tabview](https://github.com/TabViewer/tabview) was a recent discovery that became immediately indispensable. It allows Excel-like viewing of CSV files from the terminal. Much of my work is done in remote terminal sessions, running jobs in parallel on high-performance computing clusters. tabview makes it easy to quickly spot-check the contents of data files from the command line like this:

```
tabview my_data.csv
```

[tqdm](https://pypi.org/project/tqdm/) displays a progress bar in the terminal when looping. It’s very easy to use and provides convenient estimates of the time elapsed, time remaining and time per iteration. Like tabview, it is very helpful when running code remotely. Here is a simple use case:

~~~python
from tqdm import tqdm

mylonglist = […]

for i in tqdm(mylonglist):
    # do stuff here
    pass
~~~

Here’s a cute demo of tqdm in action:

![tqdm demo](https://warehouse-camo.cmh1.psfhosted.org/1e5bc2088d8bd1edf2ddaaffa21435c0fee10a03/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f7471646d2f7471646d2f6d61737465722f696d616765732f7471646d2e676966)

## Visualisation

![seaborn](https://tryolabs.com/images/blog/post-images/2017-03-16-pandas-seaborn-a-guide-to-handle-visualize-data-elegantly/heatmap_2.994292b9.png)

[seaborn](https://seaborn.pydata.org) is a high-level package for data visualisation built on top of matplotlib. It contains a few dozen core plotting functions, all of which try to do something useful when called with a minimal set of arguments. Plots are customisable through additional parameters. It also contains a number of ‘themes’ and colour maps that can be applied to any matplotlib plots (not just those from seaborn) to make them more visually appealing or suitable for publication.

![cmocean](https://matplotlib.org/cmocean//index-2.hires.png)

[cmocean](https://matplotlib.org/cmocean) provides additional colour maps for matplotlib. They were designed with oceanography in mind, but in my opinion they are the best colour maps currently available for Python regardless of scientific area. I’m currently using them for plotting heritability estimates on the human cortical surface.

Speaking of cortical surfaces, the author of seaborn also produced [PySurfer](https://pysurfer.github.io). Unfortunately, it doesn’t work in Python 3.

## Data analysis

[patsy](https://patsy.readthedocs.io/en/latest/) (‘it’s only a model’) uses an R-like mini language to create design matrices for statistical models such as for linear regression. I use it in conjunction with other statistical packages like PyMC3 (see below).

[PyMC3](https://docs.pymc.io) is the current state-of-the-art package for Bayesian statistical inference. It contains many of the same features as [Stan](http://mc-stan.org), such as Hamiltonian Monte Carlo and variational inference. I have used this package in published work[<sup>1</sup>]. Recently it was announced that [Theano](http://deeplearning.net/software/theano/) (on which PyMC3 relies for much of its computation) was no longer being developed. It remains to be seen whether this decision will impede the development of PyMC3 in the long run. For the time being, however, it is [continuing to evolve](https://discourse.pymc.io) and I will continue to use it in future projects.

[HDDM](http://ski.clps.brown.edu/hddm_docs/index.html) is a Python package for fitting the drift-diffusion model to experimental data from tasks of two-choice decision making. It is a somewhat niche package. It depends on PyMC2, which is now obsolete. It would be great if it could be re-written with PyMC3 …

[SymPy](http://www.sympy.org/en/index.html) is a package for symbolic mathematics. It is useful when working with complex equations. Just define your variables and the relationships between them, and use SymPy automatically solve, simplify, differentiate, and so on. It provides similar functionality to [Mathematica](https://www.wolfram.com/mathematica/) without the cost. I haven’t used it much yet but plan to in the near future.

## Psychological experiments

[pygame](https://www.pygame.org/news) is a package for making multimedia applications (like games) built on top of the SDL library. The developers themselves describe pygame as ‘not the best game library’, and is intended as a learning tool rather than a serious package. In the early days of my career I wrote many of my experiments using pygame (I was just starting out, after all). I ended up relying on it for far too long simply because I didn’t want to re-write my code. I wouldn’t recommend it for serious use.

[PyQt5](https://www.riverbankcomputing.com/software/pyqt/download5) ([Qt5](https://www.qt.io) bindings for Python) is my pygame replacement. PyQt5 has a steeper learning curve than pygame, but once you get used to its highly object-oriented, signal-and-slots model it is actually incredibly powerful and easy to use. It is the primary package behind the new version of my neuropsychological battery, [Charlie 2](https://github.com/sammosummo/Charlie2/tree/master/charlie2).

[Brian](http://brian2.readthedocs.io/en/stable/index.html) is another niche package, this time for modelling neuronal spiking. I only ever used its sub-package [Brian Hears](http://brian2.readthedocs.io/en/stable/_modules/brian2/hears.html?highlight=hears), which contained some very nice classes and functions for sound synthesis, for running psychoacoustical experiments. `brian` was superseded by `brain2`, however `brian hears` wasn’t ported along with it.

[loris](http://www.cerlsoundgroup.org/Loris/) is yet another niche package I’ve used for sound modelling and synthesis.

## Miscellany

![](https://warehouse-camo.cmh1.psfhosted.org/349ea03393e3978f232fe28675ec52c3d165b810/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616d62762f626c61636b2f6d61737465722f646f63732f5f7374617469632f6c6f676f322d726561646d652e706e67)

[Black](https://pypi.org/project/black/) (‘any colour you like’) is an ‘uncompromising’ Python code formatter. Black can be called from the command line like this:

```
black myscript.py
```

The script is formatted in-place according the package’s own rules without the user having any choice in the matter. In my opinion, this is a great idea. It ensures that your code is highly readable and removes the temptation to waste time on hand-formatting.

## Packages I don’t use

I’ve tried to use [MayaVi](https://docs.enthought.com/mayavi/mayavi/) a couple of times but always found it too difficult.

[PsychoPy](http://www.psychopy.org) is a package designed specifically for psychological experiments. Given my background, I should have been all over PsychoPy, but I never really liked it and wrote a lot of what it could do from scratch myself. Perhaps it has improved over time, but I no longer have much use for it.

[<sup>1</sup>]: https://doi.org/10.1016/j.schres.2017.08.015 "Mathias, S. R., Knowles, E. E. M., Barrett, J., Beetham, T., Leach, O., Buccheri, S., Aberizk, K., Blangero, J., Poldrack, R. A., & Glahn, D. C. (2017). Deficits in visual working-memory capacity and general cognition in African Americans with psychosis. Schizophrenia Research, in press."









