---
layout: post
title: "Bayesian model of recognition memory"
date: 2017-11-22
categories:
- Bayesian
- Psychophysics
description:
image: https://sammosummo.github.io/images/glass-tears-1932.jpg
image-sm: https://sammosummo.github.io/images/glass-tears-1932-sm.jpg
image-description: "Glass Tears (1932) by Man Ray"
---
Signal detection theory (SDT) is useful tool for studying recognition memory[<sup>1</sup>]. Here, I describe a Bayesian hierarchical SDT model suitable for analysing data from recognition-memory experiments[<sup>2</sup>], and fit it to some publicly available data[<sup>3</sup>].

[<sup>1</sup>]: https://www.ncbi.nlm.nih.gov/pubmed/4867890 "Kintsch, W. (1967). Memory and decision aspects of recognition learning. Psychological Review, 74(6), 496–504."

[<sup>2</sup>]: https://doi.org/10.1016/j.jmp.2008.02.001 "Morey, R. D., Pratte, M. S., & Rouder, J. N. (2008). Problematic effects of aggregation in zROC analysis and a hierarchical modeling solution. Journal of Mathematical Psychology, 52, 376–388."

[<sup>3</sup>]: https://doi.org/10.1098/rsos.150670 "Weidemann, C. T., & Kahana, M. J. (2016). Assessing recognition memory using confidence ratings and response times. Royal Society Open Science, 3(4), 150670."

A typical recognition-memory experiment consists of two phases. During the learning phase, subjects are presented with a sequence of stimuli (items). Later, during the test phase, subjects are presented with a mixture of new items (*foils*) and old items (*targets*), and are required to discriminate them. Recognition-memory experiments often use confidence ratings. For example, subjects may be asked whether they remember the items by choosing from the following response options: ‘definitely no’, ‘perhaps no’, ‘don’t know’, ‘perhaps yes’, and ‘definitely yes’.

Let $$y$$ denote a subject’s response on a given trial with $$y =1$$ denoting ‘definitely no’, $$y=2$$ denoting ‘perhaps no’, and so on. The probability distribution of $$y$$ can be written as follows: 

$$
y\sim\textrm{Categorical}\left(p_1,p_2,\dots{},p_K\right)
$$

where $$K$$ is the number of response options. Note that $$y$$ obviously differs on each trial, and so should the probabilities Usually, we would include $$y$$ and $$p$$ a subscript $$i$$ to index the subject and a subscript $$j$$ to index the trial. I’ve omitted them here for readability.

Every SDT model contains a *perceptual* component and a *decision* component (see [<sup>4</sup>]). The perceptual component describes how *observations* are generated. We assume that on each trial, the subject creates an observation corresponding to the perceived familiarity of the item, denoted by $$\psi$$. A negative value of $$\psi$$ means that the item is perceived as unfamiliar, whereas a positive value means that the item is perceived as familiar. When the stimulus is a foil, $$\psi$$ is drawn from a Gaussian probability distribution with mean $$d_\textrm{foil}$$ and variance $$s_\textrm{foil}^2$$. When the stimulus is a target, $$\psi$$ is drawn from a Gaussian probability distribution with mean $$d_\textrm{target}$$ and variance $$s_\textrm{target}^2$$. Without any loss of generality, we set $$s_\textrm{foil}^2=1$$, and since the foil variance is fixed, it is more convenient to denote the target variance simply by $$s^2$$. We can write this as

$$
\psi\sim\textrm{Normal}\left(d_\textrm{foil}, 1\right)\textrm{ if }z=0\\  
\psi\sim\textrm{Normal}\left(d_\textrm{target}, s^2\right)\textrm{ if }z=1\\  
$$

Where $$z$$ denotes the type of item with $$z=0$$ for foils and $$z=1$$ for targets. A more compact way to write this is

$$
\psi=d_\textrm{foil}\left(1-z\right) + d_\textrm{target}z + s^z\varepsilon
$$

where $$\varepsilon\sim\textrm{Normal}\left(0, 1\right)$$[<sup>4</sup>]. The parameters $$d_\textrm{foil}$$, $$d_\textrm{target}$$, and $$s$$ are free to vary across subjects and trials, although again I have omitted $$i$$ and $$j$$ subscripts for readability.

[<sup>4</sup>]: https://doi.org/10.1016/j.jmp.2011.01.002 "DeCarlo, L. T. (2011). Signal detection theory with item effects. Journal of Mathematical Psychology, 55, 229–239."

The decision component of the model describes how responses are generated. Responses are based on $$\psi$$ in relation to several criteria, denoted by $$c$$. Specifically, the decision rule is

$$
y=k\textrm{ if }c_{k-1}<\psi\le{}c_k
$$

where $$c=-\infty$$ if $$k=0$$, and $$c=\infty$$ if $$k=K$$. The values of the remaining $$K-1$$ criteria depend on whether $$K$$ is an even or odd integer. To understand why, consider the figure below, which illustrates a model with $$K=4$$:

The middle criterion, $$c_2$$ corresponds to ambivalence — an item which is perceived as neither unfamiliar not familiar. We therefore set $$c_2=0$$, and allow the other criteria, denoted by $$c_1 and c_3$$, to freely vary. Now consider a model with $$K=5$$:

Allowing all four criteria to vary would result in this model having two more free parameters than the $$K=4$$ model, which is not what we want. My solution is constrain the two inner criteria such that $$c=-u/2$$ if $$k=(K-1)/2$$ and $$c=u/2$$ if $$k=(K+1)/2$$, where $$u$$ is free to vary. This means that the criteria are all centred around 0, just like in the $$K=4$$ model, and we have only one more free parameter per unit increase in $$K$$. Another desirable feature is that $$u$$ is interpretable: it reflects the propensity of the subject to select the middle, or ‘don’t-know’, option.

As a side note, while the decision process theoretically allows criteria to vary between subjects and items, in practice they are almost always assumed to be stable across items. Whether this is true in reality is a big can of worms. We could, if we wanted, extend the model to test this assumption; perhaps I’ll do this in a future post. For now, interested readers may wish to consult the excellent paper on this topic by Cabrera and colleagues[<sup>5</sup>].

[<sup>5</sup>]: https://doi.org/10.1016/j.jmp.2011.01.002 "Cabrera, C. A., Lu, Z. L., & Dosher, B. A. (2015). Separating decision and encoding noise in signal detection tasks. Psychological Review, 122(3), 429–460."

With the decision and perceptual components defined, we can derive the following conditional probabilities

$$
\textrm{Pr}\left\{y=k\mid{}z=0\right\}=\Phi\left(d_\textrm{foil}-c_{k-1}\right)-\Phi\left(d_\textrm{foil}-c_{k}\right)\\
\textrm{Pr}\left\{y=k\mid{}z=1\right\}=\Phi\left(\frac{d_\textrm{target}-c_{k-1}}{s}\right)-\Phi\left(\frac{d_\textrm{target}-c_{k}}{s}\right)
$$

Note that these equations are different to the ones presented in Morey’s formulation of the model[<sup>2</sup>]; I think the equations in that paper are the result of a typesetting error.

The above can be written more compactly as

$$
p_k=\left[\Phi\left(d_\textrm{foil}-c_{k-1}\right)-\Phi\left(d_\textrm{foil}-c_{k}\right)\right]\left(1-z\right)\\+\left[\Phi\left(\frac{d_\textrm{target}-c_{k-1}}{s}\right)-\Phi\left(\frac{d_\textrm{target}-c_{k}}{s}\right)\right]z
$$

A classic finding from studies of recognition memory is that the target variance is greater than the foil variance (i.e., $$s^2>1$$). It has been suggested that this could be related to aggregating over subjects and/or items, rather than a feature of memory per se. This possibility was investigated by Pratte and colleagues[<sup>6</sup>], who applied a Bayesian hierarchical SDT model (developed in their earlier paper[<sup>2</sup>]) which separated subject/item effects and memory-based effects on the data. Following these authors, we will allow the foil and target means to vary across subjects and across items in our model:

[<sup>6</sup>]: https://doi.org/10.1037/a0017682 "Pratte, M. S., Rouder, J. N., & Morey, R. D., (2010). Separating mnemonic process from participant and item effects in the assessment of ROC asymmetries. Journal of Experimental Psychology: Learning, Memory, and Cognition, 36(1), 224–232."

$$
d_{\textrm{foil}_{i_j}}=\mu^{(d_{\textrm{foil}})}+\eta^{(d_{\textrm{foil}})}\alpha^{(d_{\textrm{foil}})}_{i}+\zeta^{(d_{\textrm{foil}})}\beta^{(d_{\textrm{foil}})}_{j}\\
d_{\textrm{target}_{i_j}}=\mu^{(d_{\textrm{target}})}+\eta^{(d_{\textrm{target}})}\alpha^{(d_{\textrm{target}})}_{i}+\zeta^{(d_{\textrm{target}})}\beta^{(d_{\textrm{target}})}_{j}\\
$$

where $$\mu$$ denotes a grand mean, $$\eta$$ denotes a standard deviation of inter-subject variability, $$\alpha$$ denotes a subject offset, $$\zeta$$ denotes a standard deviation of inter-item variability, $$\beta$$ denotes an item offset, and $$i$$ and $$j$$ index the subject and item, respectively. This parameterisation is intended to avoid funnelling when performing MCMC sampling.

I have chosen the following priors on the new parameters:

$$
\mu^{(d_{\textrm{foil}})},\mu^{(d_{\textrm{target}})}\stackrel{\textrm{iid}}{\sim}\textrm{Normal}\left(0,1\right)\\
\eta^{(d_{\textrm{foil}})},\eta^{(d_{\textrm{target}})}\stackrel{\textrm{iid}}{\sim}\textrm{Half-Cauchy}\left(1\right)\\
\alpha_i^{(d_{\textrm{foil}})},\alpha_i^{(d_{\textrm{target}})}\stackrel{\textrm{iid}}{\sim}\textrm{Normal}\left(0,1\right)\\
\zeta^{(d_{\textrm{foil}})},\zeta^{(d_{\textrm{target}})}\stackrel{\textrm{iid}}{\sim}\textrm{Half-Cauchy}\left(1\right)\\
\beta_j^{(d_{\textrm{foil}})},\beta_j^{(d_{\textrm{target}})}\stackrel{\textrm{iid}}{\sim}\textrm{Normal}\left(0,1\right)
$$

It is conceivable that the target standard deviation, $$s$$, may vary across subjects. It is less plausible that it would differ across items. We  also need to ensure that it is always positive.

$$
s_{i_j}=\exp\left({\mu^{(s)}+\eta^{(s)}\alpha^{(s)}_{i}}\right)\\
\mu^{(s)},\alpha_i^{(s)}\stackrel{\textrm{iid}}{\sim}\textrm{Normal}\left(0,1\right)\\
\eta^{(s)}{\sim}\textrm{Half-Cauchy}\left(1\right)\\
$$
